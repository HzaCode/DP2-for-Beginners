# Core Concepts in DP2
## Study

In the DP2 platform, the **Study** function allows users to plan and execute data processing activities in a project-oriented manner. Each study instance is designed as an integrated project container, consisting of a series of well-defined steps. Each step targets a specific segment of the data processing workflow. This includes precise extraction of web content, in-depth parsing of HTML code, to extracting valuable information from complex data structures. The global variables defined in a study can be shared among steps, aiming to reduce repetitive configuration work, thereby improving the efficiency and flexibility of project execution. This design enables users to quickly adjust and optimize processing strategies for different data processing needs.

## Step

Within the research framework of the DP2 system, a **Step** is the fundamental unit that constitutes the skeleton of a study, responsible for achieving specific objectives in the data processing flow. Each step contains a series of detailed configuration information, covering key aspects such as target URLs, HTTP request methods (GET or POST), data to be submitted, and cookies configuration. In addition, steps offer highly configurable solutions for data input (Data In) and output (Data Out), supporting advanced data querying and transformation operations using JMESPath to accommodate complex data processing scenarios.

## Task

In the DP2 platform, a **Task** refers to an operational instance defined by steps, automatically assigned to designated worker nodes for execution. The types of tasks are extremely diverse, covering a range of operations from precise extraction of web content, deep parsing of data structures, to effective extraction of specific information. Upon completion, the output data from tasks can provide necessary input for subsequent steps or be directly stored in databases, supporting the continuous accumulation and flow of data.

## Worker Node

Worker nodes are the execution units within the DP2 data processing architecture, which can be built on physical servers or cloud-based virtual machines. By adopting a distributed technological architecture, DP2 efficiently distributes tasks across multiple worker nodes, significantly enhancing the speed and overall efficiency of data processing. This design ensures the system can handle large-scale data requests, guaranteeing high parallelism and quick response in task processing.

## Data Input (Data In) & Data Output (Data Out)

In the step configurations of DP2, the data input and output functions provide a flexible data flow scheme for the entire data processing workflow. The data input specifies the data foundation required before executing a task, which may include a fixed data set or data dynamically generated by a previous step. The data output defines the results produced after executing a step, which not only can support the execution of subsequent steps but can also be pushed to external databases through API interfaces for storage. This flexible configuration option for data input and output enables the DP2 platform to effectively support complex data processing tasks and meet diverse business needs.

## JMESPath

**JMESPath** is a language specifically designed for querying and transforming JSON data. It enables users to effectively filter, sort, and map data within complex JSON structures through a series of query expressions. By leveraging JMESPath, users can simplify the data extraction and transformation process, significantly improving the efficiency and accuracy of data processing.

## API (Application Programming Interface)

The DP2 platform provides strong API support, allowing users to seamlessly integrate and push the results of data processing to external systems, such as various types of database systems. Moreover, DP2 also offers direct support for popular database systems (such as MySQL and MongoDB), further facilitating users' management and analysis work after data processing, enhancing the flexibility and breadth of data applications.

## XPath

**XPath** is a powerful tool for finding information in HTML or XML documents, precisely locating specific parts of a document through accurate path expressions. In the DP2 data processing framework, the application of XPath makes data extraction from markup documents more efficient and accurate.

## Special Table Data Processing

Faced with specially formatted or constantly changing table data, the DP2 platform offers a flexible and powerful processing mechanism. By configuring precise XPath and JMESPath query rules, users can effectively extract key information from these changing tables, meeting specific data processing needs. This special data processing functionality allows the DP2 platform to handle various complex data scenarios, ensuring the accuracy and effectiveness of data extraction.

## Attachment Handling and Storage

Considering the need to process attachments in data processing tasks, the DP2 platform specifically provides functionality for downloading and storing attachments. The system supports securely processing and storing attachments as Object Storage Service (OSS) keys, ensuring data integrity and security. This feature offers convenience in handling data tasks that include attachments, enhancing the platform's data processing capabilities.

## Data Updates and Notifications

To keep users informed of the latest developments in data processing, the DP2 platform supports configuring real-time data update notification mechanisms. With simple settings, users can receive email or WeChat message notifications of data updates, allowing real-time monitoring of the status and results of data processing. This mechanism provides an efficient project management and monitoring tool for users, ensuring transparency and traceability in data processing activities.

To ensure consistency with the specified Markdown document style, here is the content translated into English and formatted accordingly:

# Operation Process

## Creating a Study

First, you need to create a study (**Study**), defining the study's name (**STU**) and steps (**steps**). The creation of a study involves setting up global variables and basic configurations for steps.

## Configuring a Step

Within a step, configure the **URL**, **method** (GET or POST), **data**, **cookies**, etc. These configurations determine how the crawler interacts with the target website. The step's configuration also includes how to handle **input data** (**Data In**) and **output data** (**Data Out**), as well as how to use **Jpath** for data processing.

## Handling Data In and Data Out

In a step, use **Data In** to receive output from the previous step, and process and output data through **Data Out**. This allows you to pass and modify data between steps, facilitating data flow and transformation.

## Using Jpath

With **Jpath**, you can precisely extract the information you need from JSON data. Jpath offers a rich set of query functionalities, such as filtering, sorting, and mapping, making data processing more flexible.

## Calling APIs

In **Data Out**, configure API calls to send data to databases or other external systems. This ensures data storage and subsequent processing. API calls can be direct or made through DP2's API.




